[["index.html", "Statistics with jamovi Welcome", " Statistics with jamovi Dana Linnell Last Update: 2024-02-11 Welcome This is the website for PSYC 290 and PSYC 790 at the University of Wisconsin-Stout, taught by Dr. Dana Linnell. These resources are aimed at teaching you how to use jamovi and null hypothesis significance testing (NHST) to answer research questions. This website is free to use and is licensed under a Creative Commons BY-SA (CC BY-SA) license version 4.0. This means you are free to share (i.e., copy and redistribute the material in any medium or format) and free to adapt (i.e., remix, transform, and build upon the material for any purpose, even commercially), provided that you attribute these resources by citing me, indicating if changes were made and you share alike (i.e., if you adapt, you must distribute your contributions under the same license as the original). Many of the data examples come from “Learning statistics with jamovi: A tutorial for psychology students and other beginners” by Danielle J. Navarro and David R. Foxcroft, version 0.70. Dedication: This book is dedicated to my graduate statistics professor Dr. Dale Berger, who gave us a similar set of resources when he taught statistics at Claremont Graduate University. I still have my binder of handouts, homework assignments, and notes, which have been instrumental throughout my career. Thank you for showing me the joy of statistics! Image of Dale Berger and Dana Linnell at her master’s graduation ceremony "],["introduction.html", "1. Introduction", " 1. Introduction This chapter will introduce you to the course, the instructor (Dr. Dana Linnell), and the textbook. 1.1 Getting help in this class Come to student hours regularly! They are often available both in-person or online, depending on whether you are enrolled in an in-person or online section of the course. I am always available to help you. Depending on the semester, there may also be a graduate assistant (GA) who can support you as well. We will be scheduling regularly recurring student hours each week so you can come ask questions, get help on your homework, or just have a space to come together to work on your assignments in a dedicated online space. If you have questions, you can message me on Teams or email me at linnellda@uwstout.edu. See your course on Canvas if you have any questions about Teams. 1.2 Dana, your instructor My name is Dana Linnell (pronounced DAY-nuh lih-NELL) and I started teaching at UW-Stout in Fall 2019. I teach statistics, research methods, interpersonal effectiveness, and evaluation in the Department of Psychology. I love statistics! It is one way we can answer our research questions and test our hypotheses. However, I know not everyone likes statistics. Some of you may not care much about it, and some of you may be apprehensive or anxious about taking this course. Please know that I am here for you and I want to make this class an enjoyable learning experience. If there is anything I can do to help make this class more enjoyable and to help you learn, please reach out to me. 1.3 Navigating this website/book This book was developed using a coding language called R in a graphical user interface called RStudio using a package called bookdown. This book is hosted on a platform called GitHub. You can see the code for this book here if you are interested. There are some icons at the top of this book that you may find useful: The first icon of the toolbar, which looks like three horizontal lines, toggles the visibility of the sidebar, which contains the table of contents. You can also hit the S key on your keyboard to toggle the sidebar. The second icon of the toolbar, which looks like a magnifying glass, is the search feature, which you can use to search the entire book. You can also hit the F (Find) key on your keyboard. The third icon, which is a capital A, is for font/theme settings, which you can use to change font size (smaller or bigger), font family (serif or sans serif), and theme (white, sepia, or night). The fourth icon, which is a lower-case i, provides information on the keyboard shortcuts. 1.4 Technology Tips To succeed in this course, you will need a computer capable of installing and running Microsoft Word, Microsoft Excel, and jamovi. The Stout Surplus store (Facebook; website) may have laptops and desktops they are selling for cheap. You may also find it useful to have a mouse in this course since we’ll be pointing and clicking a lot in jamovi; you can get small portable ones to bring with you to campus if you’re in my in-person section. You may also find it beneficial to have two monitors in this course. When doing activities and assignments in this course, I recommend having jamovi open on one monitor and then the assignment and textbook open on the other monitor. The Stout Surplus store may have extra monitors they are selling for cheap. If you are unable to get a second monitor in this course, learn how to snap windows side by side in Windows or Mac. Learn also how to use the Alt+Tab function on your computer as well to switch back and forth from open applications. For Macs, use Cmd+Tab. When you are working on this course, I recommend that you only have open the application and windows you actually need for this course. Ample research has shown that multitasking does not work, and so when you switch from one activity to another (e.g., from working on another course to this one) you should wrap up your tasks, save your files, close them all, and then start fresh. This will clean up your taskbar and help you focus on this course. It will also free up your computer’s resources so it won’t start slowing down. Another friendly reminder: restart your computer frequently, at least once a week. Your computer will begin slowing down the longer you wait in between restarts. Also, be sure to update your computer regularly. Note that jamovi also has a Cloud version. The free version will not be sufficient for all this course, but you can pay for the cloud version if you wish. Please note that the desktop version is strongly recommended as it is free and should work fine with the minimum technical specifications of computers that Stout requires. 1.5 Errors, mistakes, and suggestions I am human, therefore I err. If you find an error in the textbook or something you think might be a mistake, please let me know ASAP so I can update this for everyone else. Let me know which section you find the error or mistake in and what the error or mistake is. For example, if there was an error here you could say, “There was an error in chapter 1, last section, that the first sentence should really be ‘To err is human (Alexander Pope, 1711).’” In addition, if you have ideas to help make this textbook even better, please let me know. I would love to make this a useful resource to you both during our course and in your future research. Help me in making that a reality! "],["statistics-foundations.html", "2. Statistics foundations", " 2. Statistics foundations You have learned about both quantitative and qualitative methods. We will be focusing primarily on quantitative methods in this class and in this textbook. By quantitative methods, I mean methods that predominantly collect data that deals with numbers. We can then analyze that data using statistical procedures, which we will shorthand to “statistics.” Understanding what we mean by statistics is the purpose of this chapter. "],["describing-our-data.html", "2.1 Describing our data", " 2.1 Describing our data First, let’s understand some basic statistics related to how we describe our data, including measures of central tendency (averages), measures of dispersion (spread), and measures of shape of the distribution (particularly a normal distribution). Measures of Central Tendency There are multiple measures of central tendency (these are all averages so you must be careful when you say that word to explain which type you mean!): Mean: the sum of all points divided by the total number of points. The mean can be susceptible to outliers. Median: the middlemost value. The median less susceptible to outliers and best used when the data is skewed. Mode: the most frequently occurring score. Our data can also be multimodal when there are multiple modes or bimodal when there are two modes. Note that depending on the shape of the distribution, the mean, median, and mode may not be the same value. If we have a normal distribution then they will be the exact same! However, if we have a positively skewed distribution, the mean and median will be pulled towards the positively skewed data, as shown in this figure by Peter Prevos. Measures of Dispersion There are also multiple measures of dispersion that describe the spread of our data: Range: the difference between the maximum and minimum value (e.g., if the minimum score is 17 and the maximum is 49, then the range is 32) Quartile: when a dataset is divided into four equal parts, the first quartile (Q1) is at the 25th percentile, the second quartile (Q2) is at the 50th percentile, and the third quartile (Q3) is at the 75th percentile. Note that the median is also the 50th percentile! Interquartile range: the middle 50% (Q1 to Q3) Variance: is the measurement of the spread between numbers in a dataset. More specifically, it is the sum of the squared deviations from the mean. This means first (a) calculating the mean, (b) subtracting each score from the mean (aka deviations from the mean), (c) squaring each of those deviations values, and (d) summing all those squared deviations. This is represented by the equation \\(\\frac{\\sum (X-\\mu)^2}{N}\\) Standard deviation: is the square of the variance. This is represented by the equation \\(\\sqrt{\\frac{\\sum (X-\\mu)^2}{N}}\\) if we are examining the whole population. If we only have a sample, we replace the denominator N with N-1. I sometimes present equations, like above, to help some folks better understand various things in this course. However, I very rarely expect you to calculate things, and when I do, I give you a lot of support in how to do so. Measures of the Shape of the Distribution We also have two main measures of shape that describe the shape of the distribution of our data: Skew: in a non-normal distribution, it is when one tail of the distribution is longer than another. Present in asymmetric distributions Negative skew: when the tail points to the negative end of the spectrum; in other words, most of the values are on the right side of the distribution Positive skew: when the tail points to the positive end of the spectrum; in other words, most of the values are on the left side of the distribution Kurtosis: the weight of the tails relative to a normal distribution. In other words, it’s how flat or skinny the distribution is. There are some fancy terms related to kurtosis that you may hear about, but honestly I don’t hear them used very frequently by researchers. Leptokurtic: light tails; values are more concentrated around the mean. Think of kangoroos which can be noted for “lepping”. Platykurtic: heavy tails; values are less concentrated around the mean. Think of a platypus! Student (a pseudonym of William Gosset) wrote this in his 1927 paper). When skew and kurtosis are zero, then we have a special type of distribution called the normal distribution in which the data are symmetrical on both sides of the mean. We sometimes call this a “bell curve”. Scribbr has a great article on the normal distribution I encourage you to read! Although there are many ways we can visualize the distribution the two most common ways we will visualize the distribution using jamovi are with a histogram which could also be a density curve or a boxplot. We’ll learn more about visualizing in Chapter 3 “Visualizing data”. "],["levels-of-measurement.html", "2.2 Levels of measurement", " 2.2 Levels of measurement This may or may not be refresher material for you, but it is extremely important you are familiar with the four levels of measurement. Categorical: variables that have categories to the levels, but cannot be analyzed with a mean because the levels are not proportionate. There are two types of categorical variables: Nominal: a categorical variable in which each level of the variable is named but there is no order to them (e.g., breeds of dogs). Nominal variables can only be analyzed with frequencies, modes, counts, or percentages. Nominal variables with only two levels (generally coded as 0 or 1, although jamovi can handle named levels), we call these special nominal variables as either binary, dummy-coded, or dichotomous nominal variables. For example, binary variables could be coded as yes or no or as absence or presence. Ordinal: a categorical variable in which each level of the variable is named and there is an order to them (e.g., ranks). We can analyze ordinal variables with frequencies and percentages, like nominal variables, but we can also analyze them using medians, minimum and maximum values, ranges, and percentiles. Continuous: variables with proportionate intervals between the levels, meaning they can be analyzed with a mean, SD, variance. There are two types of continuous variables (although for the purpose of this course we will simply call them continuous variables): Interval: a continuous variable that has intervals that are directly proportionate (e.g., the distance between 2-3 is the same as the distance between 5-6). We can analyze interval variables using means, variances, and standard deviations. Ratio: a continuous variable like an internal variable but can accommodate an absolute zero, meaning a zero is actually possible (e.g., weight, temperature in Kelvin, reaction time). We can also analyze ratio variables with means, variances, and standard deviations, but we can also conduct arithmetic operations like fractions and ratios. Note that in this class, I won’t ask you to differentiate between interval and ratio levels of measurement because the differences between the two are usually not meaningful in our work. You’ll even find that jamovi doesn’t differentiate between the two, either. Instead, you just need to know whether the variables are continuous, ordinal, or nominal. Examples of levels of measurement Confused still on the levels of measurement? Maybe this will help! One semester, a student asked, “Isn’t time a continuous variable?” To which I responded, “It depends on how it is measured!” If time was measured in a simple pre/post design, such as the start of the semester and the end of the semester, then it’s a nominal variable, and a specific type of nominal variable that we can call binary or dichotomous. If time was measured by month, January through December, then it would be ordinal because January is before (earlier than) February, for example. There is an order to the months, and a calendar that went March, October, April, January, etc. would make no sense. If time was measured as a continuous variable, it could be something like the exact day, exact time, response time, or time remaining. Here’s another example. Notice that studying can be measured at different levels. Depending on the nature of the question and response options, it might be nominal, ordinal, or continuous! Here’s an example of data at the continuous, ordinal, and nominal level. Name Study_Continuous Study_Ordinal Study_Nominal Name (Character) Hours studied per day Likert scale of amount of studying Whether or not they study every day Jesus 5.0 A great deal Yes Nicky 4.5 A great deal Yes Bradford 3.2 A moderate amount Yes Sylvia 1.7 A small amount Yes Martha 0.2 Rarely Yes Lillian 0.0 Never No Trayvon 0.0 Never No We can make any continuous variable into an ordinal and nominal variable and any ordinal variable into a nominal variable. But if we have a nominal variable we cannot make it ordinal, nor can we make an ordinal variable continuous. In other words, continuous variables contain more information than categorical variables. Often, we want to avoid losing information and so we should aim to keep the variable at the highest level of measurement. Because continuous variables have more information, we want to avoid doing things like mean or median splits or “collapsing” categories when you can. A mean or median split, which involves finding the mean or median value and splitting the data so it’s above the mean/median or below the mean/median, is making a continuous variable as nominal, which is removing information. Collapsing categories may also further reduce the information. Another thing to keep in mind is that just because we put numbers to something does not necessarily make it continuous! Be careful and think critically. If I said cat = 1, dog = 2, and frog = 3 it doesn’t make it an ordinal or continuous variable. "],["descriptive-vs-inferential-statistics.html", "2.3 Descriptive vs inferential statistics", " 2.3 Descriptive vs inferential statistics There are basically two different types of statistics: Descriptive statistics are used to summarize, organize, and overall describe our sample data. Typically, we do so using measures of central tendency (e.g., mean, median, mode), measures of dispersion (e.g., range, standard deviation, variance), and shape (e.g., skew, kurtosis). We may also visualize the data using tables or graphs. Inferential statistics are what we use when we collect data about a sample and see how well that sample infers things about the population from which the sample comes from. Typically, we do so with statistical tests like the t-test, ANOVA, correlation, chi-square, regression, and more. We can visualize the relationship between the population, sample, descriptive statistics, and inferential statistics (see figure below). We are typically interested in a population of interest but may not be able to collect data from the entire population because of budget, time, access, or other constraints. Therefore, we typically sample from the population; ideally, we do so randomly, but there are other types of sampling methods available that are covered in research methods. We then use descriptive statistics to describe our sample data, and we and inferential statistics to make generalizations about the population from which they were selected. Note that we typically use both descriptive and inferential statistics. However, some studies may be purely descriptive with no inference back to the population. We typically always describe the sample when we are performing inferential statistics though. An example This has been pretty abstract so far. Let’s go through a fairly simple research study to walk through all of this. Imagine we’re conducting an experimental study examining whether watching Schitt’s Creek–a very good show–versus watching video lessons on studying techniques–useful, but boring–improved test performance in UW-Stout students. Our population of interest is therefore all UW-Stout students, roughly 9,500 students total. We cannot include them all in our study; it wouldn’t be feasible for us to collect all that data and probably not possible to get the university to get on board with the study of the entire student body. Therefore, we smartly decide to only collect data from a sample of the student body. Who might our sample be? Ideally, we’d gather a random sample of the 9,500 students. However, to do that we’d likely need to still get university approval and get a list of a portion of student emails for recruitment purposes (oversampling because our response rate is unlikely to be 100%). I just want to do this study to show what descriptive and inferential statistics are, so I just use students in my two sections of introduction to psychology classes (around 80 students total) as my population. This is definitely not a random sample, but a fine study for our illustrative purposes. We conduct our study–let’s assume we’re fabulous researchers and it worked out perfectly. We randomly assign half our students to watch Schitt’s Creek as part of their studying, and the other half watch video lessons on studying techniques. They have an exam a week later and we measure their accuracy on that exam. We then want to know: which group performed better on the exam? First, let’s describe the sample. We would likely visualize our results, perhaps as a histogram of all test scores, maybe separated by which group they were in. This would help us look at whether our data is normally distributed (more on this in a subsequent chapter on assumption checking). We would get the descriptive statistics: probably the mean, maybe the median if our data is skewed, the standard deviation and variance, and the range. If we wrote up our results and didn’t share a visualization, this information would give a good sense of our data to our readers. But what we really want to know is: which group performed better on the test? For that, we need our mean, standard deviations, and sample sizes for both groups. We then plug the numbers into the equation for this particular inferential statistic (in this case, an independent t-test, but we’ll learn about that later) or–even better–we perform the statistic in our statistical software (jamovi). It spits out our statistical value and our p-value and we can then infer what the results mean for our population and answers our research question.1 You might be wondering: well, what were the results? Which group performed better? As much as I love Schitt’s Creek, most students don’t know how to study well, and so the students who watched the video lessons on studying techniques far outperformed the students who watched Schitt’s Creek. Interested in better techniques for studying? Check out The Learning Scientists. This article does a good job of summarizing the research on effective study practices.↩︎ "],["design-methods-key-terms.html", "2.4 Design &amp; Methods Key Terms", " 2.4 Design &amp; Methods Key Terms The following covers some terminology that will be helpful to keep in mind throughout the semester. Variables We tend to talk about two different types of variables in our studies: Independent variable (IV; also known as the predictor variable or exposure variable): this is the variable that is thought to be the cause of some effect. In experimental research, it is the variable that is manipulated. Dependent variable (DV; also known as the outcome variable): this is the variable that is thought to be affected by changes in the IV. In research, it is the variable that is measured. There are other types of variables we may be interested in. Note that these variables are not considered independent variables because we would not manipulate them or try to examine how they cause the dependent variable. Confounding variable: a variable that affects or is related to both the independent and dependent variable Covariate: a variable that only affects or is only related to the dependent variable Study design terms Some terms you should be familiar with: Between-group/subject design: in a study, participants are only exposed to a single condition. In other words, there are different people in each condition. Correlational research: a study in which causality cannot be claimed; correlation does not infer causation! It is, however, one of three necessary conditions to infer causality. It is a necessary but insufficient alone condition. Cross-sectional research: also called non-experimental research; the IV is not manipulated and there is no random assignment. Furthermore, data is only collected at one time point (as opposed to longitudinal research) Experimental research: the IV is manipulated and there is random assignment Falsification: A key way we separate science from pseudo-science is that we attempt to falsify our hypotheses as opposed to verify our hypotheses. Null hypothesis significance testing (NHST) is about falsifying the null hypothesis; we can never truly verify our alternative hypothesis. Hypothesis: What we think the answer to our research question is (often our alternative hypothesis). The alternative and null hypotheses must be mutually exclusive (a result can’t satisfy both) and exhaustive (all possible results are specified) Alternative hypothesis: Often that the IV had an effect on the DV; can be specified as a two-tailed (an effect) or one-tailed (greater/less than) hypothesis Null hypothesis: The null hypothesis is the opposite of the alternative hypothesis and encompasses all the rest of the possibilities. A special type of null hypothesis is the nill hypothesis which is that there is no effect on the DV. Qualitative methods: Broadly, methods that focus on words and meaning (e.g., interviews) Quantitative methods: Broadly, methods that focus on numbers and statistics (e.g., Likert scales) Quasi-experimental research: the IV is manipulated but there is no random assignment Randomization: participants are randomly assigned to conditions Repeated-measures design: participants are repeatedly measured on the dependent variable, either across conditions or across time Theory: A description of a behavior that makes predictions about future behaviors Variation: Systematic: researcher introduces error systematically into the study, especially into one condition over another. For example, by randomly assigning participants into one of two conditions, we are introducing systematic variability between participants. However, it could be unintentional systematic variation; for example, perhaps we have two researchers collecting data and one is mean and the other is nice, and so participants respond differently depending on which researcher collects data from them. Unsystematic: random variation Within-group/subject design: in a study, participants are exposed to every condition. In other words, there are the same people in each condition. Reliability and validity Reliability: the consistency of a measure by time (test-retest reliability), across items (internal consistency) or across different researchers (inter-rater reliability). Check out the chapter “Reliability” for more information on measuring reliability. Validity: the extent to which a test measures what it claims to measure Construct validity: validity of inferences about the higher order constructs that represent sampling particulars. There are multiple types of construct validity; here are a few: Content validity: experts using their judgment that something measures what it is supposed to measure Convergent validity: correlations among two theoretically related constructs (or measurements) are strong and positive Divergent validity: correlations among two theoretically not-related constructs (or measurements) are zero/null Criterion validity: content on one test (predictor) correlates with performance on relevant criterion measures (outcome) Statistical validity: validity of inferences about the correlation between treatment and outcome Internal validity: validity about whether the observed relationship between A and B reflects a causal relationship between A and B External validity: validity of inferences about whether the cause-effect relationship holds over variation in persons, places, treatment variables, and measurement variables Statistical terms Degrees of freedom (df): Degrees of freedom are the number of values that are free to vary and are not constrained. The easiest way to understand them is with an example of the mean. If you know the sum of 4 numbers, then 3 of those numbers are free to vary but the fifth value is dependent on (and constrained) to the values of the other. If your sum is 10, you could have three random values of 2, 3, and 1 (which are free to vary) but your fourth number must be 4. Therefore, the degrees of freedom in this example would be 3, which is n - 1. The statistical tests all have different ways of calculating degrees of freedom. For example, the one-sample t-test is n - 1, the independent t-test is n1 + n2 - 2, and the dependent t-test is n - 1 where n is the number of pairs. Confidence intervals: A confidence interval is such that in repeated sampling (e.g., replicating a study over and over and over again) then 95% of those confidence intervals should contain the true population parameter. You can see this visualized, and learn more about it, with this great visualization and read this great blog post. You can also read a chapter on this topic by Daniel Lakens. Other terms If other terms come up in the course of the semester that you believe should belong in this key term website, include it in your weekly reflection so I can update this page! "],["overview-of-jamovi.html", "3. Overview of jamovi", " 3. Overview of jamovi jamovi is a free and open statistical software that helps us run our descriptive and inferential statistics. Why are we using jamovi and not another program? Did I mention it’s free? You won’t ever have to pay a dime to use the software in the future. It’s open source, meaning that the statistical community helps support and improve the program. As jamovi says, “jamovi is made by the scientific community, for the scientific community.” It’s built on top of the R statistical language, meaning you can begin learning how to code (if you want). I do all of my statistical analyses using R in a different program called RStudio (actually this book was developed in RStudio and hosted on GitHub!). It’s a very powerful tool which is also free and open source. It’s incredibly easy to learn and use. I have taught statistics using both SPSS and jamovi, and students greatly prefer jamovi. It promotes reproducibility. jamovi will save your data, analyses, options, and results all in one file so you can easily pick up where you left off. This will make your homework and future data analyses a breeze. Additional jamovi videos and resources Here are some additional resources on jamovi I recommend you bookmark and use when you are struggling or need additional support: jamovi 2022 tutorials by Alexander Swan on YouTube jamovi docs provide more support for using jamovi, including tips for transitioning from SPSS to jamovi and from jamovi to R caution: these use an older version of jamovi! Introduction to jamovi LinkedIn Learning course by Barton Poulson, founder of datalab.cc (you can find the video on YouTube and other places now, too, if you do not have LinkedIn Learning) Navigating the jamovi interface I recommend you watch this video by Alexander Swan on navigating the jamovi interface in jamovi to understand everything. Note that he is using a Mac in his demonstrations and that he has downloaded a ton of add-on modules which is why his Analyses tab looks different from yours. Opening data in jamovi I recommend you watch this video by Alexander Swan on opening files in jamovi. I occasionally get questions on how to open .sav files (SPSS files) in jamovi. Here’s a video walking you through that. Entering data in jamovi Occasionally you need to manually enter data into jamovi instead of opening a pre-existing data file. I recommend you watch this video by Alexander Swan on entering data manually in jamovi. Annotating output in jamovi Sometimes I may ask you to submit a file of your output with annotations. I recommend you watch this video by Alexander Swan on annotating output in jamovi. "],["describing-data.html", "Describing data", " Describing data As a reminder, descriptive statistics are used to summarize, organize, and overall describe our sample data. Data variables First, it’s important to understand the different types of variables in jamovi and how they map onto our levels of measurement. Variables in jamovi can be one of three data types: Integer, meaning the values are discrete whole numbers Decimal, meaning the values are numbers with decimals Text, meaning the values are alphanumeric, not just numeric Furthermore, variables in jamovi can be one of four measure types: Nominal Ordinal Continuous (meaning jamovi combines interval and ratio and doesn’t distinguish between the two) ID (used for any identifying variable you likely wouldn’t ever analyze, like participant ID number or name) There are a few great things about jamovi when it comes to these data variables. First, jamovi will try to automatically determine what the data and measure types are when you type in data or when you open a dataset; this is fabulous, until it goes wrong. It’s important that you always double check your data and measure types first! Second, those little icons will be really helpful to let you know what variables can go in which boxes. For example, we would never analyze a nominal variable as our dependent variable for a t-test, and jamovi will help remind you of that. When performing an independent samples t-test, the dependent variables box will have a little ruler icon indicating you should be putting continuous variables in that box. Similarly, it will tell you to put nominal or ordinal variables in the grouping variable (independent variable) box. Sweet! Describing your data We explore our data partly to describe our data and partly to check our data before performing inferential statistics. jamovi puts all our descriptive statistics into one useful analysis under the Analyses tab within the Exploration menu called Descriptives. Describing nominal or ordinal data Nominal and ordinal data is described mainly using frequencies. Choose your categorical variable(s) and move it to the Variables box and then select the option Frequency tables. Note that it tells you it’s best for nominal and ordinal data with the two icons! I recommend you watch this video by Alexander Swan on how to describe categorical data in jamovi. Describing continuous data Continuous data is described using a variety of measures of central tendency, dispersion, and more. Choose your continuous variable(s) in the list of variables on the left side and move it to the Variables box. I recommend you watch this video by Alexander Swan on how to describe continuous data in jamovi. In the Descriptives analysis, these are under the Statistics drop-down menu. There are a ton of possible options! Sample size: you can ask for the sample size (N) and number of missing values (Missing) Percentile values: these are useful for creating quartiles (Cut points for 4 equal groups) or Percentiles of various sizes. Dispersion: you should already be familiar with most of the measures of dispersion, particularly the Minimum and Maximum, but there is also the Std. deviation (SD) and Variance (which is just SD2). We’ll learn about the S. E. Mean later. Central Tendency: similarly, you should also be familiar with all of the measures of central tendency: Mean, Median, Mode, and Sum. Distribution: you should also be familiar with both Skewness and Kurtosis and later we will learn what those values mean and how that helps us test for normality Normality: lastly, there is a statistical test for normality called the Shapiro-Wilk test that we will learn about later. Describing one variable split by another variable Sometimes we want to get the descriptive statistics for one variable across multiple groups of another variable. Usually, this is a continuous variable split by a categorical variable. In that case, move your continuous variable to the Varables box and the variable you want split by categories in to the Split by box. Writing up descriptive statistics We’ll learn more about writing up our inferential statistics results later, but first let’s learn how we might report our descriptive statistics. In small examples, we might write-up our descriptive statistics into a paragraph2 (note that there is also an independent t-test and a chi-square test of independence!): In examples with many variables, we might write-up our descriptive statistics into a table3: This comes from Wanzer (2017) Developmentally appropriate evaluations: How evaluation practices differ across age of participants↩︎ This comes from Wanzer et al. (2020) Experiencing flow while viewing art: Development of the aesthetic experience questionnaire↩︎ "],["visualizing-data.html", "Visualizing data", " Visualizing data “A picture is worth a thousand words,” and in a world in which journal articles have word count limits, figures and graphs are priceless. They are also an incredibly powerful way to examine your data because it can often illuminate patterns you may not be able to see through a table. jamovi has some plots built into its platform, both under the Plots drop-down menu in the Descriptives analysis and as options for many of the inferential statistical analyses. We’ll learn more about how to choose and conduct better data visualizations later, but for now here are some recommended visualizations depending on what you are trying to do. Note that we will do most of our visualizations in jamovi, but we may also learn how to visualize data via Excel. There are also excellent LinkedIn Learning courses on data visualization in Excel and other tools that I strongly recommend; they are free for you if you are a UW-Stout student. When you want to visualize the distribution of a continuous variable First, there are two Histogram options: Histogram and Density. These are useful for seeing the overall distribution of your data and to help check for normality. Which should you use? I think they’re both pretty great, and in fact you can combine the two to have a histogram plot with a density overlay. I like this option best because it presents more information and better lets us see if the if the density curve looks normally distributed. When you want to visualize the distribution of a continuous variable split by a categorical variable There are three options under Box Plots: Box plot, Violin (which is really a density plot with its mirror image!), Data (which can be Jittered or Stacked; I prefer Jittered so you can see the density of data points really well), and Mean. Personally, I love checking all four boxes! This gives you the best of all them: the distribution of your data with the Violin option, the quartiles and mean with the Box plot option, a visualization of all your data points using the Data option, which is really useful because the other two options can be hiding weird things in your data, and what the Mean is. When you want to visualize the frequencies of a categorical variable For this you would choose the single option under Bar Plots: Bar plot. It will simply show the frequencies of a categorical variable. Remember: it is incredibly important to always visualize your data! You never know what descriptive statistics may be hiding. Expanding your data visualization Although these can be useful plots, I often do most of my data visualizations in other platforms. For most of my work, I use Excel because I find it pretty easy to make beautiful graphs. Here’s an example of a visualization I made in Excel4: For some more complicated figures, I turn to the ggplot2 package in R. Here’s an example of a visualization I made in R5: This comes from Wanzer et al. (2020) Promoting intentions to persist in computing: An examination of six years of the EarSketch program↩︎ This comes from Wanzer (2020) What is evaluation? Perspectives of how evaluation differs (or not) from research↩︎ "],["cleaning-data.html", "Cleaning data", " Cleaning data There are four basic types of cleaning we will be learning about: checking your data is setup correctly, computing new variables, transforming variables, and using filters. The following video walks through some of these data cleaning techniques. Data setup As previously mentioned, it’s really important to check that the data types and measurement types of your variables are correct. You should open the Setup () option under the Data tab to check. When you’re in Setup, here’s the things you should be doing for all variables: Make sure the variable name is meaningful to you. You may also want to change it to something that will appear nicely in your data visualizations or tables (e.g., don’t write Q35 but rather BDI Score). Add a description to your variable so you have more context. Maybe you write Average score of all BDI items for the description of your BDI Score variable. Check your measure and data types are correct. Specify if there is a code for missing values. Make sure the code does not match the code you use for actual variables! For example, if I have a variable that ranges from 0-10, then I wouldn’t use 9 as a code for missing values; instead, I might use 99 or -9. Add labels to levels. For example, the variable Athlete is 0 for non-athlete and 1 for athlete. Rather than keeping just the 0 and 1, you can specify under Levels that 0 is non-athlete. Compute (create new variables using some computation) Sometimes you need to create new variables from your raw (meaning uncleaned) data. I recommend you watch this video by Alexander Swan on computing variables in jamovi. Perhaps you collected data on a scale that has five items. Normally, we create an average score of all the five items and that new computed average score is what we use in our analyses. Let’s open the Big 5 dataset built into jamovi. You can open this dataset by clicking the three horizontal lines on the top left of jamovi (the menu), choose Open, then select Data Library. In the main Data Library folder is a dataset called Big 5. This dataset has the scores on all five subscales of the Big Five personality test. Let’s imagine we want the average score of the entire Big Five test. We would click on the Data tab and choose Compute. We would rename the computed variable (e.g., Big5_Avg), add in a description, and then create the formula. In this case, we need to select the function MEAN. Below the function, it provides a template of what the formula should look like. We need to specify the function MEAN(), add all the variables we want to calculate in the mean (i.e., the five subscales of the Big 5), and there are two alternative options: ignore_missing is defaulted to 0 (meaning DON’T ignore missing, or rather include missing) and min_valid is defaulted to 0 (meaning it’s ignoring this; perhaps you only want to include people that have at least three valid cases). The basic formula, then is to do MEAN(var1, var2, … varn). You can see what we need to do with this dataset below. There’s actually no missing data, so the two additional arguments aren’t necessary for us to worry about. Note that this was creating an average score using the MEAN() function. Sometimes, psychological scales want you to create a total score using the SUM() function. jamovi also has a lot of other functions you may need to use in the future. If you’d like to learn more about computed variables in jamovi, check out this jamovi blog post on the topic. Transform (revise current variables) Sometimes we want to take an existing variable and transform it in some way or we want to do a computation across multiple variables (e.g., reverse-score multiple items in a dataset). I recommend you watch this video by Alexander Swan on transforming variables in jamovi. If you want to learn more about transforming variables, the jamovi blog has a great blog post on the topic. Recoding Maybe we want to recode variables. Perhaps we want to recode the Neuroticism scale into low, moderate, and high extraversion. The scale ranges from 1-5, so I’m going to say that scores between 1-2.333 are low, 2.334 to 3.666 is moderate, and 3.667 to 5 is high. First, I create a new Transform variable: Then I need to specify the transformation. Click Edit to do so (or, when creating a new transformation, click the transformation and select Create New Transform). We need to specify the recode conditions. Click Add recode condition twice. For the first formula, we want to specify that if the $source (meaning the score for the variable we’re using for the transformation, in this case Neuroticism) is less than or equal to 2.333, then it will be recoded as low. We do the same for moderate. Then we can end with an else statement: all other values (else) are recoded as high. We can either let it auto determine the measure type, but I like to be in control of my data and therefore specify it is an ordinal variable. Notice the use of apostrophes around the text! We need to do this because jamovi thinks we’re recoding the numeric variable as another numeric variable. By wrapping in apostrophes or quotation marks, we are telling jamovi that it will be text. Reverse-scoring Sometimes items need to be reverse-scored because they are in the opposite direction of the entire scale. Let’s imagine we have a Happiness Scale with the following four items: I am happy. I am content. Life is overall positive. I am unhappy. The happiness scale suggests that higher scores is higher happiness, but the fourth item is opposite. Higher scores on that item actually indicate lower happiness. Therefore, we would need to use “Transform” to recode the items so the highest score is the lowest score and so on. For example, if it were rated on a 5-point scale then you would need to recode so a 1 = 5, 2 = 4, 3 = 3, 4 = 2, and 5 = 1. We would do this using the recode function like so. Imagine the item was #1 in the “Scale”. Note that we use a double equal sign in jamovi (this is part of the R language). Multiple transformations Maybe we instead want to do a transformation across multiple variables. Perhaps we have multiple items that need to be reverse-scored. Or maybe like in our first example above we want to use our previous Low_mod_high transformation to perform on all the subscales of the Big 5. We can click a new variable (e.g., Openness), select Transform, rename the variable, and select the Low_mod_high transformation we already used. Voila! The work we did previously can easily be used again in this analysis. Filters Sometimes we only want to analyze certain pieces of our data. We can filter by rows and by columns. Check out this blog post by jamovi on more details of filters. Row filters Maybe we only want to analyze data from people who are low in neuroticism. We would create the following filter: You’ll notice in the dataset it will add a new column named Filter 1 (the name of the filter) and there will either be an X or a green check mark indicating whether it’s removed (X) or kept (check) in the analyses. If you want to take off the filter, but keep it available, click on the filter column and toggle the green button on the top right from active to inactive. It will then grey out the column. A couple things to note: Notice that to say it equals to low you have to use a double equal sign: == Another common thing you may want to specify is that the variable is not equal to something. You would use the following: != Otherwise you should be familiar with the other operations: &lt;, &gt;, &lt;=, &gt;= Column filters Column filters are useful when you want to use a filter for some but not all of your analyses. Rather than creating a filter, we need to compute a new variable using the FILTER() function. For example, we learned how to reverse score our hypothetical happiness item above. We could then say we only want people who are high in that variable for another analysis. We could apply a column filter that is FILTER(Scale1_Reverse_Scored, Scale1_Reverse_Scored &gt; 3) . "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
